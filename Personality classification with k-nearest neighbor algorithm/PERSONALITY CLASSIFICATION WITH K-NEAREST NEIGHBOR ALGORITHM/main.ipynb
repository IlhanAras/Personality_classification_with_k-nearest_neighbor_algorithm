{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class KNN:\n",
    "        def __init__(self, k=3):\n",
    "            self.k = k\n",
    "        \n",
    "        def fit(self, X, y): #X=X_train   y=y_train\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "        \n",
    "        def predict(self, X): # predict function predicts personality \n",
    "            y_pred = []     #this list is result  predict list of this func \n",
    "            for x in X:\n",
    "                # calc distance between values of x \n",
    "                distances = self.calculate_distance(x)\n",
    "                indices = np.argpartition(distances, self.k)[:self.k]\n",
    "                nearest_neighbors = [self.y[i] for i in indices]\n",
    "                nearest_neighbors = [int(i) for i in nearest_neighbors]\n",
    "                \n",
    "                most_common = Counter(nearest_neighbors).most_common(1)\n",
    "                y_pred.append(most_common[0][0])\n",
    "            return y_pred   \n",
    "        \n",
    "        def calculate_distance(self, x):\n",
    "            #calc distance by using numpy linear norm\n",
    "            distances = np.linalg.norm(self.X - x, axis=1)\n",
    "            return distances\n",
    "\n",
    "\n",
    "        def confmatrixmaker(self,prediction,y_test):\n",
    "            # will create confusion matrix\n",
    "            confusion_matrix = np.array([[0 for _ in range(16)] for _ in range(16)]) #empty matrix\n",
    "\n",
    "            # Iterate through the true labels and predicted labels\n",
    "            for true, pred in zip(y_test, prediction):\n",
    "                confusion_matrix[true][pred] += 1  # Increment the value in the confusion matrix         \n",
    "            return confusion_matrix\n",
    "\n",
    "        def accur(self,matr,y_test):#calc accuracy\n",
    "            accurlist=[]    #this list will contain accuracy of each k-fold\n",
    "            for row_colrecall in range(16):    # calc macro\n",
    "                accurlist.append(matr[row_colrecall,row_colrecall])\n",
    "                \n",
    "            return(sum(accurlist)/len(y_test))\n",
    "\n",
    "        def precisioncalc(self,matr):#calc precision \n",
    "            precilis=[]       #this list will contain precision of each k-fold\n",
    "            for row_col in range(16):# calc macro precision by using precision values of precilis \n",
    "                precilis.append(matr[row_col,row_col]/(matr[:,row_col].sum()))\n",
    "            return(sum(precilis)/len(precilis))   \n",
    "\n",
    "\n",
    "        def recallcalc(self,matr):#calc precision \n",
    "            recallist=[]   #this list will contain recall of each k-fold\n",
    "            for row_colrecall in range(16):# calc macro recall by using recall values of recallist \n",
    "                recallist.append(matr[row_colrecall,row_colrecall]/(matr[row_colrecall,:].sum()))\n",
    "            return(sum(recallist)/len(recallist)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 9999\n",
    "\n",
    "dft = pd.read_csv('data_set.csv',sep=\",\", encoding='cp1252')\n",
    "df=pd.DataFrame(dft)      # load data and turn into pandas dataframe\n",
    "\n",
    "\n",
    "df.drop( columns='Response Id',inplace=True) # dropped Response Id \n",
    "# encoded personolity from str to int\n",
    "personality_dict = {         \n",
    "    \"ESTJ\": 0,\n",
    "    \"ENTJ\": 1,\n",
    "    \"ESFJ\": 2,\n",
    "    \"ENFJ\": 3,\n",
    "    \"ISTJ\": 4,\n",
    "    \"ISFJ\": 5,\n",
    "    \"INTJ\": 6,\n",
    "    \"INFJ\": 7,\n",
    "    \"ESTP\": 8,\n",
    "    \"ESFP\": 9,\n",
    "    \"ENTP\": 10,\n",
    "    \"ENFP\": 11,\n",
    "    \"ISTP\": 12,\n",
    "    \"ISFP\": 13,\n",
    "    \"INTP\": 14,\n",
    "    \"INFP\": 15\n",
    "}\n",
    "\n",
    "df[\"Personality\"] = df[\"Personality\"].map(personality_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anacalisir(nparr): # main work func\n",
    "    pr_independent= nparr[:, :-1]# set target and predictor\n",
    "    tar_dependent= nparr[:, -1:] \n",
    "    for a in range(1,10,2):  #this for loop makes k=1,3,5,7,9 \n",
    "\n",
    "\n",
    "        num_rows = df.shape[0]\n",
    "\n",
    "        # calculate the size of each fold\n",
    "        fold_size = num_rows // 5\n",
    "\n",
    "        # set the starting index for the first fold\n",
    "        start_index = 0\n",
    "\n",
    "        accur_average_list=[]\n",
    "        precision_average_list=[]\n",
    "        recal_average_list=[]\n",
    "\n",
    "\n",
    "        # Loop through the 5 folds\n",
    "        for i in range(5):\n",
    "            \n",
    "            # calculate the ending index for the current fold\n",
    "            end_index = start_index + fold_size\n",
    "            \n",
    "            # check if this is the last fold\n",
    "            if end_index > num_rows:\n",
    "                # If it is, set the ending index to the last row\n",
    "                end_index = num_rows\n",
    "            \n",
    "            # Split the data into train and test sets\n",
    "            X_test = pr_independent[start_index:end_index]\n",
    "            y_test = tar_dependent[start_index:end_index]\n",
    "            X_train = np.concatenate((pr_independent[:start_index], pr_independent[end_index:]))\n",
    "            y_train = np.concatenate((tar_dependent[:start_index], tar_dependent[end_index:]))\n",
    "\n",
    "            #set knn k=a ,a defined in the for loop 1,3,5,7,9\n",
    "            knn = KNN(k=a)\n",
    "            knn.fit(X_train, y_train) # fit trains arrays\n",
    "\n",
    "            y_test=y_test.flatten() # flatten the arrays due to some future bugs\n",
    "            y_test=np.array(list(map(int,y_test)))\n",
    "            y1d_test=np.array(y_test).flatten()\n",
    "\n",
    "            # will predict result\n",
    "            prediction=knn.predict(X_test)\n",
    "\n",
    "            confusion_matrix=knn.confmatrixmaker(prediction,y_test) # makes confusion matrix\n",
    "\n",
    "            # average lists for recall precision and accuracy\n",
    "            precision_average_list.append(knn.precisioncalc(confusion_matrix))\n",
    "            accur_average_list.append(knn.accur(confusion_matrix,y_test))\n",
    "            recal_average_list.append(knn.recallcalc(confusion_matrix))\n",
    "            start_index += fold_size\n",
    "\n",
    "        # print results\n",
    "        print(\"k=\",a)    \n",
    "        print(\"precision:\\t\",(sum(precision_average_list)/5))    \n",
    "        print(\"recall:\\t\",(sum(recal_average_list)/5))\n",
    "        print(\"accuracy:\\t\",(sum(accur_average_list)/5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalize true\n",
      "\n",
      "k= 1\n",
      "precision:\t 0.9737752096074164\n",
      "recall:\t 0.9737077341549872\n",
      "accuracy:\t 0.9737144762063504\n",
      "k= 3\n",
      "precision:\t 0.9876644922008755\n",
      "recall:\t 0.9876448325345372\n",
      "accuracy:\t 0.9876489707475622\n",
      "k= 5\n",
      "precision:\t 0.9885223762197626\n",
      "recall:\t 0.9885108732363792\n",
      "accuracy:\t 0.9885157096424703\n",
      "k= 7\n",
      "precision:\t 0.9887545241026778\n",
      "recall:\t 0.9887419473079742\n",
      "accuracy:\t 0.9887490624218686\n",
      "k= 9\n",
      "precision:\t 0.9888729582597969\n",
      "recall:\t 0.9888653056563401\n",
      "accuracy:\t 0.9888657388115677\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def normalize(X):   # this func normalize values of data set (0-1)ranges\n",
    "    min_vals = np.min(X, axis=0)\n",
    "    max_vals = np.max(X, axis=0)\n",
    "    return (X - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "\n",
    "for colname in df.columns[:-1]:\n",
    "    flatcol=np.array(df[colname]).flatten()\n",
    "    df[colname]=normalize(flatcol)\n",
    "\n",
    "nparr = df.to_numpy()\n",
    "print(\"normalize true\\n\")# with normalize\n",
    "anacalisir(nparr) #work main anacalisir func\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalize false\n",
      "\n",
      "k= 1\n",
      "precision:\t 0.9778342577301988\n",
      "recall:\t 0.9778015267996316\n",
      "accuracy:\t 0.9778148179014916\n",
      "k= 3\n",
      "precision:\t 0.9884830003425475\n",
      "recall:\t 0.9884587293792176\n",
      "accuracy:\t 0.9884657054754562\n",
      "k= 5\n",
      "precision:\t 0.9890504944176399\n",
      "recall:\t 0.9890236238913616\n",
      "accuracy:\t 0.9890324193682807\n",
      "k= 7\n",
      "precision:\t 0.9892273733260109\n",
      "recall:\t 0.9892116075917116\n",
      "accuracy:\t 0.9892157679806651\n",
      "k= 9\n",
      "precision:\t 0.9893756156332406\n",
      "recall:\t 0.9893627175543781\n",
      "accuracy:\t 0.9893657804817068\n"
     ]
    }
   ],
   "source": [
    "nparr = df.to_numpy()  #without normalize\n",
    "print(\"normalize false\\n\")\n",
    "anacalisir(nparr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error Analysis for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above results show us that normalizing will calculate data faster and have higher accuracy,recall and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this mini code for shown confussion matrix k=1\n",
    "\n",
    "def showmatrix(nparr): # main work func\n",
    "    pr_independent= nparr[:, :-1]# set target and predictor\n",
    "    tar_dependent= nparr[:, -1:] \n",
    "    for a in range(1,2):   \n",
    "        num_rows = df.shape[0]\n",
    "\n",
    "        # calculate the size of each fold\n",
    "        fold_size = num_rows // 5\n",
    "\n",
    "        # set the starting index for the first fold\n",
    "        start_index = 0\n",
    "\n",
    "        accur_average_list=[]\n",
    "        precision_average_list=[]\n",
    "        recal_average_list=[]\n",
    "\n",
    "\n",
    "        # Loop through the 5 folds\n",
    "        for i in range(5):\n",
    "            \n",
    "            # calculate the ending index for the current fold\n",
    "            end_index = start_index + fold_size\n",
    "            \n",
    "            # check if this is the last fold\n",
    "            if end_index > num_rows:\n",
    "                # If it is, set the ending index to the last row\n",
    "                end_index = num_rows\n",
    "            \n",
    "            # Split the data into train and test sets\n",
    "            X_test = pr_independent[start_index:end_index]\n",
    "            y_test = tar_dependent[start_index:end_index]\n",
    "            X_train = np.concatenate((pr_independent[:start_index], pr_independent[end_index:]))\n",
    "            y_train = np.concatenate((tar_dependent[:start_index], tar_dependent[end_index:]))\n",
    "\n",
    "            #set knn k=a ,a defined in the for loop 1,3,5,7,9\n",
    "            knn = KNN(k=a)\n",
    "            knn.fit(X_train, y_train) # fit trains arrays\n",
    "\n",
    "            y_test=y_test.flatten() # flatten the arrays due to some future bugs\n",
    "            y_test=np.array(list(map(int,y_test)))\n",
    "            y1d_test=np.array(y_test).flatten()\n",
    "\n",
    "            # will predict result\n",
    "            prediction=knn.predict(X_test)\n",
    "\n",
    "            confusion_matrix=knn.confmatrixmaker(prediction,y_test) # makes confusion matrix\n",
    "            return confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[736   2   0   2   3   2   0   1   4   2   1   1   0   1   2   1]\n",
      " [  0 771   4   2   0   3   0   0   3   0   1   0   0   1   4   1]\n",
      " [  1   1 733   0   1   1   1   1   2   0   1   1   1   0   1   0]\n",
      " [  2   0   1 721   0   0   0   0   0   0   0   0   2   0   1   1]\n",
      " [  0   1   2   0 717   2   0   3   0   4   0   0   3   0   1   1]\n",
      " [  3   1   0   0   2 757   1   1   0   3   0   1   3   2   0   1]\n",
      " [  0   2   1   4   3   1 743   0   1   3   0   1   1   1   0   2]\n",
      " [  5   5   1   4   3   1   0 745   0   1   3   0   1   0   2   0]\n",
      " [  0   1   1   1   1   2   1   2 732   3   0   1   1   0   0   1]\n",
      " [  3   2   1   1   0   1   3   3   1 716   0   1   2   0   0   2]\n",
      " [  2   1   2   2   0   2   6   1   2   0 727   0   0   2   3   2]\n",
      " [  4   0   1   2   2   0   1   2   1   1   0 710   1   1   2   0]\n",
      " [  0   0   2   0   3   3   2   0   2   1   1   0 716   3   1   1]\n",
      " [  0   3   1   4   3   0   0   1   0   0   0   6   6 741   1   1]\n",
      " [  0   0   1   1   2   1   1   7   1   5   0   1   1   2 711   3]\n",
      " [  3   4   2   3   2   1   4   2   0   1   0   1   0   2   2 706]]\n"
     ]
    }
   ],
   "source": [
    "print(showmatrix(nparr)) # this is the confusion matrix of prediction  k=1 and 5-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think knn algorithm is slow. If it includes na values, we must get rid of na etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm may not calculate outliers correctly because euclidean finds distance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7cb47c4e853960b415106bd979ad59fd2104ff338f4f1facf2c88369adf3f6e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
